{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319edc43-5fec-4eb4-9f61-499af2073818",
   "metadata": {},
   "source": [
    "This notebook is dedicated to visualizing the data to help understand more what it looks like, and setting up the scripts that will clean up the data for 3D Sparse Tensor Network model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369bda70-0edc-4210-9b32-22070836c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os.path\n",
    "import click\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b17c67-2667-4d48-80f1-8a0151e82320",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The h5 file should be copied from the directory provided in the *data* Slack channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e16cda-054a-4ee9-86d9-d181ce83f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADFROM = \"../mg22simulated/\"\n",
    "H5 = \"output_digi_HDF_Mg22_Ne20pp_8MeV.h5\"\n",
    "\n",
    "file = h5py.File(LOADFROM + H5, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab7a11-59ed-448c-a535-285286dae944",
   "metadata": {},
   "source": [
    "Format the data into a numpy array. The conversion from h5 to numpy array takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b8a68-278a-4301-9c7e-9f539ef726a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(LOADFROM + H5, 'r')\n",
    "\n",
    "original_keys = list(file.keys())\n",
    "original_length = len(original_keys)\n",
    "\n",
    "event_lens = np.zeros(original_length, int)\n",
    "for i in range(original_length):\n",
    "    event = original_keys[i]\n",
    "    event_lens[i] = len(file[event])\n",
    "    \n",
    "ISOTOPE = 'Mg22'\n",
    "file_name = ISOTOPE + '_w_key_index'\n",
    "# **only doing this if the file doens't exist already, as the conversion takes a while**\n",
    "if not os.path.exists(LOADFROM + file_name + '.npy'):\n",
    "    event_data = np.zeros((original_length, np.max(event_lens), 13), float) \n",
    "    for n in range(len(original_keys)):\n",
    "        name = original_keys[n]\n",
    "        event = file[name]\n",
    "        ev_len = len(event)\n",
    "        #converting event into an array\n",
    "        for i,e in enumerate(event):\n",
    "            instant = np.array(list(e))\n",
    "            event_data[n][i][:12] = np.array(instant)\n",
    "            event_data[n][i][-1] = float(n) #insert index value to find corresponding event ID\n",
    "    np.save(LOADFROM + file_name, event_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7858de7-bd31-4273-ae11-89203d5d90c0",
   "metadata": {},
   "source": [
    "Check the shape of the data. It should be (10000, 1476, 13)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86599f71-769e-40e9-ad88-bc7384f28c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(LOADFROM + ISOTOPE + '_w_key_index' + '.npy')\n",
    "print(f'Data Shape = {data.shape}') # Expected output: (10000, 1476, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844070d-ef7d-4c30-89db-d22856726e17",
   "metadata": {},
   "source": [
    "We only want to use the x, y, z, amplitude, and track ID columns, so we will slice out the useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc522c72-e337-4858-b270-0bef87fcc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice useful elements\n",
    "# [0] - x, [1] - y, [2] - z, [4] - amp, [5] - track_id \n",
    "sliced_data = data[:, :, [0, 1, 2, 4, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a213cd7-4361-4fbd-a994-7f1dcaaf0c96",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "We need to understand what are the useful parts of the data, since there are junk events with empty beam. To do that, we want to understand the distribution of the data and visualize it with plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fddfa-0f1f-41df-b816-0c036537beaf",
   "metadata": {},
   "source": [
    "First, we look at the distribution of the number of detections for each event. This is a good indicator of empty events, as the number of detections will give us an idea of which events are simply single beam junk events.\n",
    "\n",
    "From the plot below, we see that a large number of events have less than around 60-70 detections, so it would be reasonable to assume those as junk beam events with no nuclear reaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05b151-1b90-40d5-a974-2b3a7c113f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 12))  # Adjusted height to accommodate both subplots\n",
    "\n",
    "# First subplot for the unlogged histogram\n",
    "plt.subplot(2, 1, 1)  # 2 rows, 1 column, 1st plot\n",
    "plt.hist(event_lens, bins=100, edgecolor='black', alpha=0.5, color='blue')\n",
    "plt.title(\"Event Lengths\")\n",
    "plt.xlabel(\"Detections\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "xticks = np.arange(0, 1600, 50)\n",
    "plt.xticks(xticks, rotation=45)\n",
    "\n",
    "# Second subplot for the logged histogram\n",
    "plt.subplot(2, 1, 2)  # 2 rows, 1 column, 2nd plot\n",
    "plt.hist(event_lens, bins=100, edgecolor='black', alpha=0.5, color='red', log=True)\n",
    "plt.title(\"Logged Event Lengths\")\n",
    "plt.xlabel(\"Detections\")\n",
    "plt.ylabel(\"Log Frequency\")\n",
    "xticks = np.arange(0, 1600, 50)\n",
    "plt.xticks(xticks, rotation=45)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa446ec4-e85c-4054-be71-59f33bb6ae86",
   "metadata": {},
   "source": [
    "Next we also want to know around how many tracks there are in an event. We can drop all tracks with track ID 0, since those are just empty detections. We see that there is a maximum of 6 tracks for an event, indicating 6 different types of particles? (What does each track ID even represent?)\n",
    "\n",
    "We see that track ID 4 has the highest frequency, indicating it is detected the most, while track ID 5, 6 are present, but are rarely detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578aa61-075d-4d1f-b4b5-1597d9109a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the tracks array and remove zeros\n",
    "tracks = sliced_data[:, :, -1]\n",
    "tracksflat = tracks.flatten()\n",
    "no_zeros = tracksflat[tracksflat != 0]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(6, 6))  # Adjusted height to accommodate both subplots\n",
    "\n",
    "# First subplot for the unlogged histogram\n",
    "plt.subplot(2, 1, 1)  # 2 rows, 1 column, 1st plot\n",
    "plt.hist(no_zeros, bins=6, edgecolor='black', color='blue', alpha=0.5)\n",
    "plt.title(\"Track Distribution (Unlogged)\")\n",
    "plt.xlabel(\"Track ID\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Second subplot for the logged histogram\n",
    "plt.subplot(2, 1, 2)  # 2 rows, 1 column, 2nd plot\n",
    "plt.hist(no_zeros, bins=6, edgecolor='black', color='red', alpha=0.5, log=True)\n",
    "plt.title(\"Track Distribution (Logged)\")\n",
    "plt.xlabel(\"Track ID\")\n",
    "plt.ylabel(\"Log Frequency\")\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f8922-73db-4e01-86db-614f0b214dad",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "As seen from the histograms above, there is a large number of events with a low number of detections. Those events are likely empty beam events, and so based on the binning of the histogram, events with under 70 detections will not be used for training. We will filter out these events. After the filtering for only events with more than 70 events, we see that there should now be 4591 events left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fee10-ffd1-4166-be81-5d6f7e71949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LENEVTS = len(sliced_data) # number of events (10000)\n",
    "LENDETS = len(sliced_data[0]) # number of detections (1476)\n",
    "NUMCLASSES = 5 # x, y, z, amp, track_id\n",
    "cutoff = 70 # discard events with less than 70 detections\n",
    "newLen = np.sum(event_lens > 70)\n",
    "\n",
    "new_data = np.zeros((newLen, LENDETS, NUMCLASSES), float)\n",
    "new_data_index = 0\n",
    "\n",
    "for i in range(LENEVTS):\n",
    "    if event_lens[i] > 70:\n",
    "        new_data[new_data_index] = sliced_data[i] \n",
    "        new_data_index += 1\n",
    "\n",
    "print(f'New Number of Events = {len(new_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da213e-f155-4211-baff-3794fc2ee903",
   "metadata": {},
   "source": [
    "## Visualizing and Plotting 3D Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b7c4ca-35ba-4b31-9b60-fa0802a71d9c",
   "metadata": {},
   "source": [
    "The following plots are to visualize what each event and their tracks look like. Each plot is event specific. Change  variable *event* to plot different events in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ba0e4-ae12-4315-9bbe-8828a0686968",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 2 # <--------- select event to plot\n",
    "selected = new_data[event]\n",
    "unique_values = np.unique(selected[:, -1])\n",
    "\n",
    "split_arrays = {}\n",
    "for value in unique_values:\n",
    "    split_arrays[value] = selected[selected[:, -1] == value]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da02252-d887-40b1-8bf1-a6b8b6f51700",
   "metadata": {},
   "source": [
    "We visualize what each track ID looks like in the following 3D plots. Each plot is for a specific track ID, with all the track IDs overlayed with each other in the final plot.\n",
    "\n",
    "We plot each of the tracks exept for the track ID of 0, as those are just empty events. Each event has 1476 detections total, but most of them are those empty events. We see this as the island of dots with an amplitude of 0 in our final plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e39a25-782a-4866-8709-9cca504b3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Each Track\n",
    "for index, (key, value) in enumerate(split_arrays.items()): \n",
    "    if key != 0.0:\n",
    "        dict_data = split_arrays[key]\n",
    "        \n",
    "        x = dict_data[:, 0]\n",
    "        y = dict_data[:, 1]\n",
    "        z = dict_data[:, 2]\n",
    "        amplitude = dict_data[:, 3]\n",
    "        log_amplitude = np.log(amplitude + 1)\n",
    "        \n",
    "        # Subplot setup\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        angles = [(30, 0), (30, 45), (30, 90), (30, 135), (30, 180), (30, 225)]\n",
    "        \n",
    "        for i, (elev, azim) in enumerate(angles, start=1):\n",
    "            ax = fig.add_subplot(2, 3, i, projection='3d')\n",
    "            sc = ax.scatter(x, y, z, c=log_amplitude, cmap='viridis', s=50)\n",
    "\n",
    "            # Set viewpoint\n",
    "            ax.view_init(elev, azim)\n",
    "            \n",
    "            ax.set_xlabel('X Label')\n",
    "            ax.set_ylabel('Y Label')\n",
    "            ax.set_zlabel('Z Label')\n",
    "            ax.set_title(f\"View: elevation={elev}, azimuth={azim}\")\n",
    "        \n",
    "        # Colorbar; since we have multiple subplots, we adjust the position for better layout\n",
    "        cax = fig.add_axes([0.92, 0.3, 0.02, 0.4]) \n",
    "        cbar = fig.colorbar(sc, cax=cax)\n",
    "        cbar.set_label('Log Amplitude')\n",
    "        \n",
    "        fig.suptitle(f\"3D Scatter Plot of Track {int(key)}, Event {event}, \")\n",
    "        plt.show()\n",
    "\n",
    "# Plot all tracks overlayed with each other  \n",
    "x = selected[:, 0]\n",
    "y = selected[:, 1]\n",
    "z = selected[:, 2]\n",
    "amplitude = selected[:, 3]\n",
    "log_amplitude = np.log(amplitude + 1)\n",
    "\n",
    "# Subplot setup\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "angles = [(30, 0), (30, 45), (30, 90), (30, 135), (30, 180), (30, 225)]\n",
    "\n",
    "for i, (elev, azim) in enumerate(angles, start=1):\n",
    "    ax = fig.add_subplot(2, 3, i, projection='3d')\n",
    "    sc = ax.scatter(x, y, z, c=log_amplitude, cmap='viridis', s=50)\n",
    "\n",
    "    \n",
    "    # Set viewpoint\n",
    "    ax.view_init(elev, azim)\n",
    "    \n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Y Label')\n",
    "    ax.set_zlabel('Z Label')\n",
    "    ax.set_title(f\"View: elevation={elev}, azimuth={azim}\")\n",
    "\n",
    "# Colorbar; since we have multiple subplots, we adjust the position for better layout\n",
    "cax = fig.add_axes([0.92, 0.3, 0.02, 0.4]) \n",
    "cbar = fig.colorbar(sc, cax=cax)\n",
    "cbar.set_label('Log Amplitude')\n",
    "\n",
    "fig.suptitle(f\"3D Scatter Plot of All Tracks, Event {event}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b545434-a99d-4e04-9141-37387d330b9f",
   "metadata": {},
   "source": [
    "## Removing the Zero Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd7b3b-8588-4330-bfcb-e0e83ae953fc",
   "metadata": {},
   "source": [
    "We currently have saved the cleaned data as numpy arrays, and they will be fed into a train-validation-test split script. But we need to get rid of the many empty zero events so that the model doesn't train on empty detections. The code below will a pipeline illustrating a small scale model to be used for testing and understanding what we are doing to the data using PyTorch's dataloader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b047b-b488-4d95-a9d0-507aab042115",
   "metadata": {},
   "source": [
    "We first load in the train test split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919fee94-4f7d-4ef9-a693-7aaa445a9d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torchsparse\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from torchsparse import SparseTensor, nn as spnn\n",
    "from torchsparse.utils.collate import sparse_collate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16258bde-3ed9-4878-bb78-4dd11b060daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, coords, feats, labels):\n",
    "        self.coords = coords\n",
    "        self.feats = feats\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.coords[idx], self.feats[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b468bb1a-b27b-4eb5-99ab-091716db4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfrom = \"../mg22simulated/\"\n",
    "ISOTOPE = \"Mg22\"\n",
    "\n",
    "coords_train = np.load(loadfrom + ISOTOPE + \"_coords_train.npy\")\n",
    "coords_val = np.load(loadfrom + ISOTOPE + \"_coords_val.npy\")\n",
    "feats_train = np.load(loadfrom + ISOTOPE + \"_feats_train.npy\")\n",
    "feats_val = np.load(loadfrom + ISOTOPE + \"_feats_val.npy\")\n",
    "labels_train = np.load(loadfrom + ISOTOPE + \"_labels_train.npy\")\n",
    "labels_val = np.load(loadfrom + ISOTOPE + \"_labels_val.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27551ab8-a401-4fab-be93-d6907ab0f389",
   "metadata": {},
   "source": [
    "We only use 100 of the events for our small scale model training and 50 events for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603afad-8dc9-4f26-ae3a-23d1516de536",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_train = coords_train[0:100]\n",
    "feats_train = feats_train[0:100]\n",
    "labels_train = labels_train[0:100]\n",
    "    \n",
    "coords_val = coords_val[0:50]\n",
    "feats_val = feats_val[0:50]\n",
    "labels_val = labels_val[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fc8ed1-5d7c-447b-874f-653a0f1f268b",
   "metadata": {},
   "source": [
    "Below we create the layers and define the criterion and opitmizer for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7930991-4e5c-4c76-ac99-fe38288be52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Settings\n",
    "device = 'cuda'\n",
    "amp_enabled = True\n",
    "\n",
    "model = nn.Sequential(\n",
    "    spnn.Conv3d(4, 32, 3),\n",
    "    spnn.BatchNorm(32),\n",
    "    spnn.ReLU(True),\n",
    "    spnn.Conv3d(32, 32, 3),\n",
    "    spnn.BatchNorm(32),\n",
    "    spnn.ReLU(True),\n",
    "    spnn.Conv3d(32, 7, 1),\n",
    ").to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scaler = amp.GradScaler(enabled=amp_enabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3872ec-6ed9-4376-8ad9-7b988b4ef2ec",
   "metadata": {},
   "source": [
    "We create our dataloaders from the training and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1049be6-77ff-446a-a737-9c7f1f5a3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 12\n",
    "\n",
    "train_set = CustomDataset(coords_train, feats_train, labels_train)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "\n",
    "val_set = CustomDataset(coords_val, feats_val, labels_val)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "train_steps = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f74bb-ae63-4a92-b095-2b990ac6ad83",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829241ee-37ff-42e9-90dd-2ea3092e1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (batch_coords, batch_feats, batch_labels) in enumerate(train_loader):\n",
    "        tr_inputs_list = []\n",
    "        tr_labels_list = []\n",
    "        \n",
    "        for i in range(len(batch_coords)):\n",
    "            current_coords = batch_coords[i]\n",
    "            current_feats = batch_feats[i]\n",
    "            current_labels = batch_labels[i]\n",
    "\n",
    "            mask = ~(current_coords == 0).all(axis=1)\n",
    "\n",
    "            # Apply the mask to the array\n",
    "            current_coords = current_coords[mask]\n",
    "            current_feats = current_feats[mask]\n",
    "            current_labels = current_labels[mask]\n",
    "            \n",
    "            current_coords = torch.tensor(current_coords, dtype=torch.int)\n",
    "            current_feats = torch.tensor(current_feats, dtype=torch.float)\n",
    "            current_labels = torch.tensor(current_labels, dtype=torch.long)\n",
    "\n",
    "            inputs_sparse = SparseTensor(coords=current_coords, feats=current_feats)\n",
    "            labels_sparse = SparseTensor(coords=current_coords, feats=current_labels)\n",
    "            tr_inputs_list.append(inputs_sparse)\n",
    "            tr_labels_list.append(labels_sparse)\n",
    "        \n",
    "        tr_inputs = sparse_collate(tr_inputs_list).to(device=device)\n",
    "        tr_labels = sparse_collate(tr_labels_list).to(device=device)\n",
    "        \n",
    "        with amp.autocast(enabled=amp_enabled):\n",
    "            tr_outputs = model(tr_inputs)\n",
    "            tr_labelsloss = tr_labels.feats.squeeze(-1)\n",
    "            print(tr_outputs.feats)\n",
    "            print()\n",
    "            print(tr_labelsloss)\n",
    "            tr_loss = criterion(tr_outputs.feats, tr_labelsloss)\n",
    "        \n",
    "        running_loss += tr_loss.item()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(tr_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "    training_losses.append(running_loss / train_steps)\n",
    "    print(f\"[Epoch {epoch+1}] Running Loss: {running_loss / train_steps}\")\n",
    "\n",
    "    model.eval()\n",
    "    torchsparse.backends.benchmark = True  # type: ignore\n",
    "    val_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd35e20-8d95-42b9-831a-f27fe423ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_test = np.load(loadfrom + ISOTOPE + \"_coords_test.npy\")\n",
    "feats_test = np.load(loadfrom + ISOTOPE + \"_feats_test.npy\")\n",
    "labels_test = np.load(loadfrom + ISOTOPE + \"_labels_test.npy\")\n",
    "\n",
    "runninglen = 0\n",
    "\n",
    "test_set = CustomDataset(coords_test, feats_test, labels_test)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "model.load_state_dict(torch.load('../training/2023-11-10-19:25:27/models/epochs100_lr0.001_2023-11-10-19:25:27.pth'))\n",
    "model.eval()\n",
    "\n",
    "torchsparse.backends.benchmark = True  # type: ignore\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_preds = np.array(all_preds)\n",
    "    \n",
    "    total_correct = 0\n",
    "    for batch_idx, (batch_coords, batch_feats, batch_labels) in enumerate(test_loader):\n",
    "        t_inputs_list = []\n",
    "        t_labels_list = []\n",
    "\n",
    "        for i in range(len(batch_coords)):\n",
    "            current_coords = batch_coords[i]\n",
    "            current_feats = batch_feats[i]\n",
    "            current_labels = batch_labels[i]\n",
    "            \n",
    "            mask = ~(current_coords == 0).all(axis=1)\n",
    "\n",
    "            # Apply the mask to the array\n",
    "            current_coords = current_coords[mask]\n",
    "            current_feats = current_feats[mask]\n",
    "            current_labels = current_labels[mask]\n",
    "            all_labels = np.concatenate((all_labels, current_labels.reshape(-1)))\n",
    "            \n",
    "            current_coords = torch.tensor(current_coords, dtype=torch.int)\n",
    "            current_feats = torch.tensor(current_feats, dtype=torch.float)\n",
    "            current_labels = torch.tensor(current_labels, dtype=torch.long)\n",
    "            \n",
    "            t_inputs_sparse = SparseTensor(coords=current_coords, feats=current_feats)\n",
    "            t_labels_sparse = SparseTensor(coords=current_coords, feats=current_labels)\n",
    "            t_inputs_list.append(t_inputs_sparse)\n",
    "            t_labels_list.append(t_labels_sparse)\n",
    "\n",
    "            runninglen += len(current_coords)\n",
    "        t_inputs = sparse_collate(t_inputs_list).to(device=device)\n",
    "        t_labels = sparse_collate(t_labels_list).to(device=device)\n",
    "\n",
    "        \n",
    "        n_correct = 0\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(t_inputs)\n",
    "            \n",
    "            labelsloss = t_labels.feats.squeeze(-1)\n",
    "            loss = criterion(outputs.feats, labelsloss)\n",
    "            _, predicted = torch.max(outputs.feats, 1)\n",
    "\n",
    "            \n",
    "            all_preds = np.concatenate((all_preds, predicted.cpu().numpy()))\n",
    "            n_correct += (predicted == labelsloss).sum().item()\n",
    "            total_correct += n_correct\n",
    "    \n",
    "    acc = 100.0 * total_correct / (len(all_preds))\n",
    "    print(f'Accuracy of the model: {acc:.3g} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843baae3-ae33-40b0-8f19-e4268ae46d07",
   "metadata": {},
   "source": [
    "## Confusion Matrices\n",
    "\n",
    "We generate confusion matrices to visualize how our model classifies each respective particle track by comparing True Labels vs Predicted Labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4baca-cef6-41a0-83f8-6c510e825cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels.astype(int), all_preds.astype(int), labels=[1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Normalize by row\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len([1, 2, 3, 4, 5, 6]))  # Assuming labels are [1, 2, 3, 4, 5, 6]\n",
    "plt.xticks(tick_marks, [1, 2, 3, 4, 5, 6])\n",
    "plt.yticks(tick_marks, [1, 2, 3, 4, 5, 6])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "thresh = cm.max() / 2\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, f'{cm[i, j]:}',\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe14bf-87ed-49fa-b187-1dd2bdb06884",
   "metadata": {},
   "source": [
    "We can also normalize the matrices by rows or columns depending on what we want to learn from the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e53d587-e10a-445b-be0c-db46bc1768c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels.astype(int), all_preds.astype(int), labels=[1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Normalize by rows\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len([1, 2, 3, 4, 5, 6]))\n",
    "plt.xticks(tick_marks, [1, 2, 3, 4, 5, 6])\n",
    "plt.yticks(tick_marks, [1, 2, 3, 4, 5, 6])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "thresh = cm_normalized.max() / 2\n",
    "for i, j in np.ndindex(cm_normalized.shape):\n",
    "    plt.text(j, i, f'{cm_normalized[i, j]:.2f}',\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm_normalized[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437b58f-b776-4102-b95b-25a6025f0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(all_labels.astype(int), all_preds.astype(int), labels=[1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Normalize by columns\n",
    "column_sums = cm.sum(axis=0)\n",
    "# Avoid division by zero\n",
    "column_sums[column_sums == 0] = 1\n",
    "cm_normalized_col = cm.astype('float') / column_sums[np.newaxis, :]\n",
    "\n",
    "plt.imshow(cm_normalized_col, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Column-Normalized Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len([1, 2, 3, 4, 5, 6]))\n",
    "plt.xticks(tick_marks, [1, 2, 3, 4, 5, 6])\n",
    "plt.yticks(tick_marks, [1, 2, 3, 4, 5, 6])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "thresh = cm_normalized_col.max() / 2\n",
    "for i, j in np.ndindex(cm_normalized_col.shape):\n",
    "    plt.text(j, i, f'{cm_normalized_col[i, j]:.2f}',\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm_normalized_col[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf5443-49c7-4d76-81c2-975e620a2fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
